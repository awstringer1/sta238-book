<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Evaluating Estimators: Efficiency and Mean Squared Error | Probability, Statistics, and Data Analysis</title>
  <meta name="description" content="This book represents part of the course materials for STA238 at the University of Toronto" />
  <meta name="generator" content="bookdown 0.21.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Evaluating Estimators: Efficiency and Mean Squared Error | Probability, Statistics, and Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book represents part of the course materials for STA238 at the University of Toronto" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Evaluating Estimators: Efficiency and Mean Squared Error | Probability, Statistics, and Data Analysis" />
  
  <meta name="twitter:description" content="This book represents part of the course materials for STA238 at the University of Toronto" />
  

<meta name="author" content="Alison Gibbs and Alex Stringer" />


<meta name="date" content="2020-10-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="section-statistical-models.html"/>
<link rel="next" href="section-introduction-to-bayesian-inference.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STA238 University of Toronto</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><i class="fa fa-check"></i><b>2</b> Introduction to Data Analysis: Data Input and Basic Summaries</a><ul>
<li class="chapter" data-level="2.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-old-faithful"><i class="fa fa-check"></i><b>2.1</b> Old Faithful</a><ul>
<li class="chapter" data-level="2.1.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-read-in-the-data"><i class="fa fa-check"></i><b>2.1.1</b> Read in the data</a></li>
<li class="chapter" data-level="2.1.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-graphical-summaries"><i class="fa fa-check"></i><b>2.1.2</b> Graphical Summaries</a></li>
<li class="chapter" data-level="2.1.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-numerical-summaries"><i class="fa fa-check"></i><b>2.1.3</b> Numerical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-drilling"><i class="fa fa-check"></i><b>2.2</b> Drilling</a><ul>
<li class="chapter" data-level="2.2.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-read-in-data"><i class="fa fa-check"></i><b>2.2.1</b> Read in data</a></li>
<li class="chapter" data-level="2.2.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-graphical-summaries-1"><i class="fa fa-check"></i><b>2.2.2</b> Graphical summaries</a></li>
<li class="chapter" data-level="2.2.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-numerical-summaries-1"><i class="fa fa-check"></i><b>2.2.3</b> Numerical summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
<li class="chapter" data-level="2.4" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-extended-example-smoking-and-age-and-mortality"><i class="fa fa-check"></i><b>2.4</b> Extended example: smoking and age and mortality</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises-1"><i class="fa fa-check"></i><b>2.4.1</b> Exercises</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-association-between-smoking-and-mortality"><i class="fa fa-check"></i><b>2.4.2</b> Association between smoking and mortality</a></li>
<li class="chapter" data-level="2.4.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises-2"><i class="fa fa-check"></i><b>2.4.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-case-study-rental-housing-in-toronto"><i class="fa fa-check"></i><b>2.5</b> Case study: rental housing in Toronto</a><ul>
<li class="chapter" data-level="2.5.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-load-the-data"><i class="fa fa-check"></i><b>2.5.1</b> Load the data</a></li>
<li class="chapter" data-level="2.5.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-analysis-i-what-does-the-data-look-like"><i class="fa fa-check"></i><b>2.5.2</b> Analysis I: what does the data look like?</a></li>
<li class="chapter" data-level="2.5.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-analysis-ii-do-different-wards-have-different-quality-housing"><i class="fa fa-check"></i><b>2.5.3</b> Analysis II: Do different wards have different quality housing?</a></li>
<li class="chapter" data-level="2.5.4" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-analysis-iii-trends-in-quality-over-time"><i class="fa fa-check"></i><b>2.5.4</b> Analysis III: trends in quality over time</a></li>
<li class="chapter" data-level="2.5.5" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-summary"><i class="fa fa-check"></i><b>2.5.5</b> Summary</a></li>
<li class="chapter" data-level="2.5.6" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises-3"><i class="fa fa-check"></i><b>2.5.6</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> Introduction to Statistics: Law of Large Numbers and Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.1" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-law-of-large-numbers-chapter-13"><i class="fa fa-check"></i><b>3.1</b> Law of Large Numbers (Chapter 13)</a><ul>
<li class="chapter" data-level="3.1.1" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-extended-example-the-probability-of-heads"><i class="fa fa-check"></i><b>3.1.1</b> Extended example: the probability of heads</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-central-limit-theorem-chapter-14"><i class="fa fa-check"></i><b>3.2</b> Central Limit Theorem (Chapter 14)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-extended-example-the-probability-of-heads-1"><i class="fa fa-check"></i><b>3.2.1</b> Extended example: the probability of heads</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-statistical-models.html"><a href="section-statistical-models.html"><i class="fa fa-check"></i><b>4</b> Statistical Models</a><ul>
<li class="chapter" data-level="4.1" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-statistical-models-chapter-17"><i class="fa fa-check"></i><b>4.1</b> Statistical models (Chapter 17)</a><ul>
<li class="chapter" data-level="4.1.1" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-linear-regression"><i class="fa fa-check"></i><b>4.1.1</b> Linear Regression</a></li>
<li class="chapter" data-level="4.1.2" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-extended-example-ttc-ridership-revenues"><i class="fa fa-check"></i><b>4.1.2</b> Extended example: TTC ridership revenues</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-unbiased-estimators-chapter-19"><i class="fa fa-check"></i><b>4.2</b> Unbiased Estimators (Chapter 19)</a><ul>
<li class="chapter" data-level="4.2.1" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-simulated-data"><i class="fa fa-check"></i><b>4.2.1</b> Simulated data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><i class="fa fa-check"></i><b>5</b> Evaluating Estimators: Efficiency and Mean Squared Error</a><ul>
<li class="chapter" data-level="5.1" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html#section-estimating-a-uniform-maximum"><i class="fa fa-check"></i><b>5.1</b> Estimating a Uniform Maximum</a></li>
<li class="chapter" data-level="5.2" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html#section-efficiency"><i class="fa fa-check"></i><b>5.2</b> Efficiency</a></li>
<li class="chapter" data-level="5.3" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html#section-mean-squared-error"><i class="fa fa-check"></i><b>5.3</b> Mean Squared Error</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html"><i class="fa fa-check"></i><b>6</b> Introduction to Bayesian Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-tutorial"><i class="fa fa-check"></i><b>6.1</b> Tutorial</a><ul>
<li class="chapter" data-level="6.1.1" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-frequentistlikelihood-perspective"><i class="fa fa-check"></i><b>6.1.1</b> Frequentist/Likelihood Perspective</a></li>
<li class="chapter" data-level="6.1.2" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-bayesian-inference-introduction"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian Inference: introduction</a></li>
<li class="chapter" data-level="6.1.3" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-flipping-more-coins"><i class="fa fa-check"></i><b>6.1.3</b> Flipping More Coins</a></li>
<li class="chapter" data-level="6.1.4" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-visualization"><i class="fa fa-check"></i><b>6.1.4</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-interactive-app"><i class="fa fa-check"></i><b>6.2</b> Interactive App</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html"><i class="fa fa-check"></i><b>7</b> The Bootstrap</a><ul>
<li class="chapter" data-level="7.1" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-the-bootstrap-chapter-18"><i class="fa fa-check"></i><b>7.1</b> The Bootstrap (Chapter 18)</a><ul>
<li class="chapter" data-level="7.1.1" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-empirical-bootstrap-old-faithful-data"><i class="fa fa-check"></i><b>7.1.1</b> Empirical bootstrap: Old Faithful data</a></li>
<li class="chapter" data-level="7.1.2" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-parametric-bootstrap-software-data"><i class="fa fa-check"></i><b>7.1.2</b> Parametric Bootstrap: software data</a></li>
<li class="chapter" data-level="7.1.3" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-extended-example-the-standard-error-of-a-proportion"><i class="fa fa-check"></i><b>7.1.3</b> Extended example: the standard error of a proportion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html"><i class="fa fa-check"></i><b>8</b> Maximum Likelihood</a><ul>
<li class="chapter" data-level="8.1" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-maximum-likelihood-chapter-21"><i class="fa fa-check"></i><b>8.1</b> Maximum Likelihood (Chapter 21)</a><ul>
<li class="chapter" data-level="8.1.1" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-example-two-coins"><i class="fa fa-check"></i><b>8.1.1</b> Example: two coins</a></li>
<li class="chapter" data-level="8.1.2" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-example-unknown-coins-n-2"><i class="fa fa-check"></i><b>8.1.2</b> Example: unknown coins, <span class="math inline">\(n = 2\)</span></a></li>
<li class="chapter" data-level="8.1.3" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-example-unknown-coins-n-bigger-than-2"><i class="fa fa-check"></i><b>8.1.3</b> Example: unknown coins, <span class="math inline">\(n\)</span> bigger than <span class="math inline">\(2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-extended-example-rental-housing-in-toronto"><i class="fa fa-check"></i><b>8.2</b> Extended example: rental housing in Toronto</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html"><i class="fa fa-check"></i><b>9</b> Confidence Intervals and Quantifying Uncertainty</a><ul>
<li class="chapter" data-level="9.1" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html#section-confidence-intervals-for-the-mean-chapter-23"><i class="fa fa-check"></i><b>9.1</b> Confidence Intervals for the Mean (Chapter 23)</a><ul>
<li class="chapter" data-level="9.1.1" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html#section-simulation-an-example"><i class="fa fa-check"></i><b>9.1.1</b> Simulation: an example</a></li>
<li class="chapter" data-level="9.1.2" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html#section-gross-calorific-value-measurements-for-osterfeld-262de27"><i class="fa fa-check"></i><b>9.1.2</b> Gross calorific value measurements for Osterfeld 262DE27</a></li>
<li class="chapter" data-level="9.1.3" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html#section-when-you-dont-know-sigma"><i class="fa fa-check"></i><b>9.1.3</b> When you don’t know <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="9.1.4" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html#section-gross-calorific-value-measurements-for-daw-mill-258gb41"><i class="fa fa-check"></i><b>9.1.4</b> Gross calorific value measurements for Daw Mill 258GB41</a></li>
<li class="chapter" data-level="9.1.5" data-path="section-confidence-intervals-and-quantifying-uncertainty.html"><a href="section-confidence-intervals-and-quantifying-uncertainty.html#section-bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>9.1.5</b> Bootstrap Confidence Intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html"><i class="fa fa-check"></i><b>10</b> Extended Example: Reasoning About Goodness of Fit</a><ul>
<li class="chapter" data-level="10.1" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-go-and-read-the-blog-post"><i class="fa fa-check"></i><b>10.1</b> Go and read the blog post</a></li>
<li class="chapter" data-level="10.2" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-distribution-of-last-digits"><i class="fa fa-check"></i><b>10.2</b> Distribution of last digits</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-read-in-the-data-1"><i class="fa fa-check"></i><b>10.2.1</b> Read in the data</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-make-the-histogram"><i class="fa fa-check"></i><b>10.2.2</b> Make the histogram</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-testing-goodness-of-fit-simulation"><i class="fa fa-check"></i><b>10.2.3</b> Testing goodness of fit: simulation</a></li>
<li class="chapter" data-level="10.2.4" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-testing-goodness-of-fit-math"><i class="fa fa-check"></i><b>10.2.4</b> Testing goodness of fit: math</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html"><i class="fa fa-check"></i><b>11</b> Bayesian Inference: Estimation</a><ul>
<li class="chapter" data-level="11.1" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-estimation-in-bayesian-inference-general-ideas"><i class="fa fa-check"></i><b>11.1</b> Estimation in Bayesian Inference: general ideas</a><ul>
<li class="chapter" data-level="11.1.1" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-the-prior"><i class="fa fa-check"></i><b>11.1.1</b> The Prior</a></li>
<li class="chapter" data-level="11.1.2" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-the-posterior"><i class="fa fa-check"></i><b>11.1.2</b> The Posterior</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-estimation-in-bayesian-inference-point-and-interval-estimation"><i class="fa fa-check"></i><b>11.2</b> Estimation in Bayesian Inference: point and interval estimation</a></li>
<li class="chapter" data-level="11.3" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-choosing-a-prior"><i class="fa fa-check"></i><b>11.3</b> Choosing a Prior</a><ul>
<li class="chapter" data-level="11.3.1" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-conjugate-priors"><i class="fa fa-check"></i><b>11.3.1</b> Conjugate Priors</a></li>
<li class="chapter" data-level="11.3.2" data-path="section-bayesian-inference-estimation.html"><a href="section-bayesian-inference-estimation.html#section-setting-hyperparameters-by-moment-matching"><i class="fa fa-check"></i><b>11.3.2</b> Setting Hyperparameters by moment-matching</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html"><i class="fa fa-check"></i><b>12</b> Predictive Modelling</a><ul>
<li class="chapter" data-level="12.1" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-overview"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-plug-in-prediction-coin-flipping"><i class="fa fa-check"></i><b>12.2</b> Plug-in prediction: coin flipping</a></li>
<li class="chapter" data-level="12.3" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-bayesian-prediction-coin-flipping"><i class="fa fa-check"></i><b>12.3</b> Bayesian Prediction: coin flipping</a></li>
<li class="chapter" data-level="12.4" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-extended-example-predicting-call-centre-wait-times"><i class="fa fa-check"></i><b>12.4</b> Extended example: predicting call centre wait times</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html"><i class="fa fa-check"></i><b>13</b> Installing R and RStudio</a><ul>
<li class="chapter" data-level="13.1" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html#section-installing-r"><i class="fa fa-check"></i><b>13.1</b> Installing R</a></li>
<li class="chapter" data-level="13.2" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html#section-installing-rstudio"><i class="fa fa-check"></i><b>13.2</b> Installing RStudio</a></li>
<li class="chapter" data-level="13.3" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html#section-using-rmarkdown"><i class="fa fa-check"></i><b>13.3</b> Using RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html"><i class="fa fa-check"></i><b>14</b> Assigned Exercises from MIPS</a><ul>
<li class="chapter" data-level="14.1" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapters-15-and-16"><i class="fa fa-check"></i><b>14.1</b> Chapters 15 and 16</a></li>
<li class="chapter" data-level="14.2" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapters-13-and-14"><i class="fa fa-check"></i><b>14.2</b> Chapters 13 and 14</a></li>
<li class="chapter" data-level="14.3" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapters-17-and-19"><i class="fa fa-check"></i><b>14.3</b> Chapters 17 and 19</a></li>
<li class="chapter" data-level="14.4" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-20"><i class="fa fa-check"></i><b>14.4</b> Chapter 20</a></li>
<li class="chapter" data-level="14.5" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-evans-and-rosenthal-chapter-7.1"><i class="fa fa-check"></i><b>14.5</b> Evans and Rosenthal, Chapter 7.1</a></li>
<li class="chapter" data-level="14.6" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-18"><i class="fa fa-check"></i><b>14.6</b> Chapter 18</a></li>
<li class="chapter" data-level="14.7" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-21"><i class="fa fa-check"></i><b>14.7</b> Chapter 21</a></li>
<li class="chapter" data-level="14.8" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-23"><i class="fa fa-check"></i><b>14.8</b> Chapter 23</a></li>
<li class="chapter" data-level="14.9" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-evans-and-rosenthal-chapter-7.2"><i class="fa fa-check"></i><b>14.9</b> Evans and Rosenthal, Chapter 7.2</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="section-extended-example-world-population-data.html"><a href="section-extended-example-world-population-data.html"><i class="fa fa-check"></i><b>15</b> Extended Example: World Population Data</a><ul>
<li class="chapter" data-level="15.1" data-path="section-extended-example-world-population-data.html"><a href="section-extended-example-world-population-data.html#section-read-in-and-prepare-the-data-for-analysis"><i class="fa fa-check"></i><b>15.1</b> Read in and prepare the data for analysis</a></li>
<li class="chapter" data-level="15.2" data-path="section-extended-example-world-population-data.html"><a href="section-extended-example-world-population-data.html#section-model-world-population-over-time"><i class="fa fa-check"></i><b>15.2</b> Model world population over time</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probability, Statistics, and Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-evaluating-estimators-efficiency-and-mean-squared-error" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Evaluating Estimators: Efficiency and Mean Squared Error</h1>
<p>This chapter introduces the concepts of Efficiency and Mean Square Error and shows
how to use them to evaluate the performance of an estimator. This material is
covered in Chapter 20 of
A Modern Introduction to Probability and Statistics.</p>
<div id="section-estimating-a-uniform-maximum" class="section level2">
<h2><span class="header-section-number">5.1</span> Estimating a Uniform Maximum</h2>
<p>In World War II, it was of interest to the Allied forces to estimate the number
of tanks that the German army had produced. German tanks had serial numbers, which
were assigned sequentially at production. That means that the largest serial number
of any tank in existence at any given time is also equal to the number of tanks
having been produced up to that point in time.</p>
<p>Whenever Allied forces captured or destroyed a tank, they would record the serial
number. Call <span class="math inline">\(X_{i}\)</span> the serial number of the <span class="math inline">\(i^{th}\)</span> tank. Assuming that</p>
<ul>
<li><p>the probability of capturing any particular tank is the same as
any other tank, and</p></li>
<li><p>that this occurs
independently of the capture of other tanks, and</p></li>
<li><p>that a tank can only be captured once,</p></li>
</ul>
<p>we would have a sample of size <span class="math inline">\(n\)</span> from a discrete uniform distribution
with maximum value <span class="math inline">\(N\)</span>, taken <strong>without replacement</strong>. The unknown value
<span class="math inline">\(N\)</span> happens to equal the number of German tanks produced, and the Allies wanted
to estimate this number using the recorded serial numbers <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>.</p>
<p>This requires constructing an estimator for <span class="math inline">\(N\)</span> using a sample of <span class="math inline">\(\text{Unif}(1,N)\)</span>
random variables. However, these samples are dependent, because the sampling is
done without replacement: once a particular tank appears in the sample, it can’t
appear again. Let <span class="math inline">\(X_{i}\)</span> be the serial numbers of the captured tanks; it can
be shown that
<span class="math display">\[\begin{equation}\begin{aligned}
E\left( \frac{1}{n}\sum_{i=1}^{n}X_{i}\right) &amp;= \frac{N+1}{2} \\
E\left(\text{max} X_{i}\right) &amp;= \frac{n}{n+1}\times(N+1)
\end{aligned}\end{equation}\]</span></p>
<p>Perhaps we should construct an unbiased estimator, given our
discussion in the previous chapter.</p>
<p><strong>Exercise</strong>: construct two unbiased estimators for <span class="math inline">\(N\)</span>, using these two results
on the expected values of the sample mean and maximum. Do this before you look at
the answer below. If you look at the answer below first, then you will learn less
from this exercise.</p>
<p>Next, let’s write functions to compute these two estimators, and use simulation
to verify that they are unbiased. At this point in the course, you should start
feeling comfortable approaching this yourself. Again, I encourage you to try this before
looking at my answer as follows:</p>
<div class="sourceCode" id="section-cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" title="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb188-2" title="2"><span class="kw">library</span>(patchwork)</a>
<a class="sourceLine" id="cb188-3" title="3"><span class="kw">set.seed</span>(<span class="dv">432354675</span>)</a>
<a class="sourceLine" id="cb188-4" title="4"><span class="co"># Functions to compute the estimators</span></a>
<a class="sourceLine" id="cb188-5" title="5">T1 &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb188-6" title="6">T2 &lt;-<span class="st"> </span><span class="cf">function</span>(x) ( (<span class="kw">length</span>(x) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="kw">length</span>(x) ) <span class="op">*</span><span class="st"> </span><span class="kw">max</span>(x) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb188-7" title="7"></a>
<a class="sourceLine" id="cb188-8" title="8"><span class="co"># Now, simulate in order to assess their bias.</span></a>
<a class="sourceLine" id="cb188-9" title="9"><span class="co"># This goes as follows (try this yourself before looking):</span></a>
<a class="sourceLine" id="cb188-10" title="10"><span class="co"># - Choose a true value of N, the parameter to be estimated</span></a>
<a class="sourceLine" id="cb188-11" title="11"><span class="co"># - Draw a sample of size n from 1:N without replacement</span></a>
<a class="sourceLine" id="cb188-12" title="12"><span class="co"># - Compute T1 and T2</span></a>
<a class="sourceLine" id="cb188-13" title="13"><span class="co"># - Repeat this M times, and compare the average of T1 and T2 to N.</span></a>
<a class="sourceLine" id="cb188-14" title="14">N &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb188-15" title="15">n &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb188-16" title="16">M &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="co"># One million simulations</span></a>
<a class="sourceLine" id="cb188-17" title="17"><span class="co"># Run the simulations. Use the sample.int() function to generate from a DISCRETE</span></a>
<a class="sourceLine" id="cb188-18" title="18"><span class="co"># uniform distribution</span></a>
<a class="sourceLine" id="cb188-19" title="19">thesimulations &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb188-20" title="20">  <span class="dt">T1 =</span> <span class="kw">numeric</span>(M),</a>
<a class="sourceLine" id="cb188-21" title="21">  <span class="dt">T2 =</span> <span class="kw">numeric</span>(M),</a>
<a class="sourceLine" id="cb188-22" title="22">  <span class="dt">T3 =</span> <span class="kw">numeric</span>(M)</a>
<a class="sourceLine" id="cb188-23" title="23">)</a>
<a class="sourceLine" id="cb188-24" title="24"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>M) {</a>
<a class="sourceLine" id="cb188-25" title="25">  <span class="co"># Do the simulation</span></a>
<a class="sourceLine" id="cb188-26" title="26">  <span class="co"># Sample from a discrete uniform (?sample.int):</span></a>
<a class="sourceLine" id="cb188-27" title="27">  thesample &lt;-<span class="st"> </span><span class="kw">sample.int</span>(N,n,<span class="dt">replace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb188-28" title="28">  <span class="co"># Record the values of the two estimators:</span></a>
<a class="sourceLine" id="cb188-29" title="29">  thesimulations<span class="op">$</span>T1[i] &lt;-<span class="st"> </span><span class="kw">T1</span>(thesample)</a>
<a class="sourceLine" id="cb188-30" title="30">  thesimulations<span class="op">$</span>T2[i] &lt;-<span class="st"> </span><span class="kw">T2</span>(thesample)</a>
<a class="sourceLine" id="cb188-31" title="31">}</a>
<a class="sourceLine" id="cb188-32" title="32"></a>
<a class="sourceLine" id="cb188-33" title="33"><span class="co"># Evaluate the bias of T1 and T2:</span></a>
<a class="sourceLine" id="cb188-34" title="34"><span class="kw">mean</span>(thesimulations<span class="op">$</span>T1) <span class="op">-</span><span class="st"> </span>N</a></code></pre></div>
<pre><code>[1] -1.7</code></pre>
<div class="sourceCode" id="section-cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" title="1"><span class="kw">mean</span>(thesimulations<span class="op">$</span>T2) <span class="op">-</span><span class="st"> </span>N</a></code></pre></div>
<pre><code>[1] 0.31</code></pre>
<p><strong>Exercise</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>What do you think about the bias of <span class="math inline">\(T_{1}\)</span> and <span class="math inline">\(T_{2}\)</span>? Repeat this whole simulation multiple times
and plot a histogram of the biases. What do you conclude?</p></li>
<li><p>Try the simulation again with a higher value of <span class="math inline">\(M\)</span>, like <span class="math inline">\(M = 10^{6}\)</span> or whatever your computer
can handle. What do you conclude?</p></li>
</ol>
<p>Finally, let’s look at the sampled values of <span class="math inline">\(T_{1}\)</span> and <span class="math inline">\(T_{2}\)</span>:</p>
<div class="sourceCode" id="section-cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" title="1"><span class="co"># Recreate the plots in Figure 20.1:</span></a>
<a class="sourceLine" id="cb192-2" title="2">leftplot &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">T1 =</span> thesimulations<span class="op">$</span>T1) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb192-3" title="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> T1)) <span class="op">+</span></a>
<a class="sourceLine" id="cb192-4" title="4"><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb192-5" title="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..),<span class="dt">bins =</span> <span class="dv">30</span>,<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>,<span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb192-6" title="6"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">300</span>,<span class="dv">700</span>,<span class="dv">1000</span>,<span class="dv">1300</span>,<span class="dv">1600</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb192-7" title="7"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">300</span>,<span class="dv">1600</span>))</a>
<a class="sourceLine" id="cb192-8" title="8"></a>
<a class="sourceLine" id="cb192-9" title="9">rightplot &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">T2 =</span> thesimulations<span class="op">$</span>T2) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb192-10" title="10"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> T2)) <span class="op">+</span></a>
<a class="sourceLine" id="cb192-11" title="11"><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb192-12" title="12"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..),<span class="dt">bins =</span> <span class="dv">30</span>,<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>,<span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb192-13" title="13"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">300</span>,<span class="dv">700</span>,<span class="dv">1000</span>,<span class="dv">1300</span>,<span class="dv">1600</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb192-14" title="14"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">300</span>,<span class="dv">1600</span>))</a>
<a class="sourceLine" id="cb192-15" title="15"></a>
<a class="sourceLine" id="cb192-16" title="16">leftplot <span class="op">|</span><span class="st"> </span>rightplot</a></code></pre></div>
<p><img src="book_files/figure-html/plots1-1.png" width="672" /></p>
<p>Remembering that <span class="math inline">\(N = 1000\)</span> in this example, do you prefer either <span class="math inline">\(T_{1}\)</span> or <span class="math inline">\(T_{2}\)</span>?</p>
</div>
<div id="section-efficiency" class="section level2">
<h2><span class="header-section-number">5.2</span> Efficiency</h2>
<p>You can often construct multiple unbiased estimators for the same problem. Are they
all as “good” as one another, or is there some reason to prefer one over another?
One way to compare estimators is by looking at their <strong>variance</strong>. If one unbiased
estimator has lower variance than another unbiased estimator, we say that the
one with lower variance is <strong>more efficient</strong> than the one with higher variance.</p>
<p>Estimators are random variables and you can calculate their variances mathematically.</p>
<p><strong>Exercise</strong>: let <span class="math inline">\(X_{i},\overset{iid}{\sim}\text{N}(\mu,1)\)</span> and suppose we have the
following two estimators for <span class="math inline">\(\mu\)</span>: <span class="math display">\[\hat{\mu}_{1} = X_{1}, \hat{\mu}_{2} = \frac{1}{n}\sum_{i=1}^{n}X_{i} = \bar{X}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Show that <span class="math inline">\(\hat{\mu}_{1}\)</span> and <span class="math inline">\(\hat{\mu}_{2}\)</span> are both <strong>unbiased estimators</strong> of <span class="math inline">\(\mu\)</span>,</p></li>
<li><p>Show that <span class="math inline">\(\hat{\mu}_{2}\)</span> is <strong>more efficient</strong> than <span class="math inline">\(\hat{\mu}_{1}\)</span>.</p></li>
</ol>
<p>Remarkably, it can be shown that there is actually a <strong>lower bound on the variance of any unbiased estimator</strong> for some likelihoods. This is called the <strong>Cramer-Rao lower bound</strong>, and states
that for a sample <span class="math inline">\(X_{i}\overset{iid}{\sim}F_{\theta}, i=1,\ldots,n\)</span> with log-likelihood <span class="math inline">\(\ell(\theta)\)</span>,
and <span class="math inline">\(\hat{\theta}\)</span> any unbiased estimator of <span class="math inline">\(\theta\)</span>, that <span class="math display">\[\text{Var}(\theta) \geq \frac{n}{-\partial^{2}\ell(\tilde{\theta}) / \partial\theta^{2}},\]</span> where <span class="math inline">\(\tilde{\theta} = \text{argmax}\ell(\theta)\)</span>, the maximum value of <span class="math inline">\(\ell(\theta)\)</span>. In order for this bound to hold,
the log-likelihood has to satisfy certain mathematical “regularity” conditions which are
outside the scope of this course.</p>
<p>When an unbiased estimator has variance which equals the lower bound, we say that
this estimator is <strong>efficient</strong>.</p>
<p><strong>Exercise</strong>: show that <span class="math inline">\(\hat{\mu}_{1}\)</span> is not efficient and that <span class="math inline">\(\hat{\mu}_{2}\)</span> is efficient,
as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Write down the log-likelihood <span class="math inline">\(\ell(\theta)\)</span> and the second derivative <span class="math inline">\(\partial^{2}\ell(\theta) / \partial\theta^{2}\)</span> for this example,</p></li>
<li><p>Compute the maximum <span class="math inline">\(\tilde{\theta} = \text{argmax}\ell(\theta)\)</span> and the curvature <span class="math inline">\(\partial^{2}\ell(\tilde{\theta}) / \partial\theta^{2}\)</span>,</p></li>
<li><p>Compare the variance of <span class="math inline">\(\hat{\mu}_{1}\)</span> and <span class="math inline">\(\hat{\mu}_{2}\)</span> to the bound <span class="math inline">\(\frac{n}{-\partial^{2}\ell(\tilde{\theta}) / \partial\theta^{2}}\)</span>.</p></li>
</ol>
<p>The discrete Uniform likelihood does not satisfy the conditions for the
lower bound to hold. However, we can compare the <strong>efficiency</strong> of <span class="math inline">\(T_{1}\)</span> and <span class="math inline">\(T_{2}\)</span>
using simulation:</p>
<div class="sourceCode" id="section-cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" title="1"><span class="kw">var</span>(thesimulations<span class="op">$</span>T1)</a></code></pre></div>
<pre><code>[1] 2985</code></pre>
<div class="sourceCode" id="section-cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" title="1"><span class="kw">var</span>(thesimulations<span class="op">$</span>T2)</a></code></pre></div>
<pre><code>[1] 71</code></pre>
<p><strong>Exercise</strong>: which estimator appears <strong>more efficient</strong> based on these simulations?</p>
<p><strong>Discussion</strong>: is the existence of a lower bound on the variance of an unbiased estimator
a good or bad thing? Consider the following points and talk about it with your classmates:</p>
<ol style="list-style-type: decimal">
<li><p>It’s a <strong>good thing</strong>, because if we want to pick an unbiased estimator to use,
we just need to find one with variance that meets the lower bound (you will see in
a subsequent chapter that this is actually really, really easy to do),</p></li>
<li><p>It’s a <strong>bad thing</strong>, since it limits how “good” an unbiased estimator can be.</p></li>
</ol>
</div>
<div id="section-mean-squared-error" class="section level2">
<h2><span class="header-section-number">5.3</span> Mean Squared Error</h2>
<p>We have seen two examples of how to evaluate the quality of an estimator <span class="math inline">\(\hat{\theta}\)</span> of
a parameter <span class="math inline">\(\theta\)</span>: its <strong>bias</strong>: <span class="math display">\[\text{bias} = E\hat{\theta} - \theta,\]</span> and its <strong>variance</strong>: <span class="math display">\[\text{Var}(\hat{\theta}) = E\left[\left(\hat{\theta} - E\hat{\theta}\right)^{2}\right].\]</span> We can combine these two into a single measure of the quality of <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p><strong>Definition</strong>: the <strong>mean squared error</strong> of an estimator <span class="math inline">\(\hat{\theta}\)</span> is the mean
of the squared error in using <span class="math inline">\(\hat{\theta}\)</span> to estimate <span class="math inline">\(\theta\)</span>: <span class="math display">\[\text{MSE}(\hat{\theta}) = E\left[\left(\hat{\theta} - \theta\right)^{2}\right].\]</span></p>
<p><strong>Exercise</strong>: show that <span class="math inline">\(\hat{\theta}\)</span> is unbiased <strong>if and only if</strong> <span class="math inline">\(\text{MSE}(\hat{\theta}) = \text{Var}(\hat{\theta})\)</span>.</p>
<p>The MSE combines the variance and the bias of an estimator as follows:</p>
<p><strong>Exercise</strong>: prove that <span class="math display">\[\text{MSE}(\hat{\theta}) = \text{Var}(\hat{\theta}) +  \text{bias}(\hat{\theta})^{2}.\]</span></p>
<p><strong>Exercise</strong>: for the Normal random sample from before, compute the <strong>MSE</strong> of <span class="math inline">\(\hat{\mu}_{1}\)</span> and
<span class="math inline">\(\hat{\mu}_{2}\)</span>.</p>
<p><strong>Exercise</strong>: for the Uniform random sample from before,</p>
<ol style="list-style-type: decimal">
<li><p>Compute the <strong>MSE</strong> of <span class="math inline">\(T_{1}\)</span> and <span class="math inline">\(T_{2}\)</span> from the simulations,</p></li>
<li><p>Show that <span class="math inline">\(T_{3} = \text{max}(X_{i})\)</span> is a <strong>biased</strong> estimator of <span class="math inline">\(N\)</span>.</p></li>
</ol>
<p>Even though <span class="math inline">\(T_{3}\)</span> is a biased estimator, is it a worse estimator that <span class="math inline">\(T_{1}\)</span>
or <span class="math inline">\(T_{2}\)</span>? We can check through simulation:</p>
<div class="sourceCode" id="section-cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" title="1">T3 &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">max</span>(x)</a>
<a class="sourceLine" id="cb197-2" title="2">mse &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">var</span>(x) <span class="op">+</span><span class="st"> </span>(<span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span>N)<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb197-3" title="3"></a>
<a class="sourceLine" id="cb197-4" title="4">thesimulations<span class="op">$</span>T3 &lt;-<span class="st"> </span><span class="kw">numeric</span>(M)</a>
<a class="sourceLine" id="cb197-5" title="5"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>M) {</a>
<a class="sourceLine" id="cb197-6" title="6">  thesample &lt;-<span class="st"> </span><span class="kw">sample.int</span>(N,n)</a>
<a class="sourceLine" id="cb197-7" title="7">  thesimulations<span class="op">$</span>T3[i] &lt;-<span class="st"> </span><span class="kw">T3</span>(thesample)</a>
<a class="sourceLine" id="cb197-8" title="8">}</a></code></pre></div>
<p>While <span class="math inline">\(T_{3}\)</span> appears to have far higher bias than <span class="math inline">\(T_{1}\)</span> or <span class="math inline">\(T_{2}\)</span>…</p>
<div class="sourceCode" id="section-cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1"><span class="kw">mean</span>(thesimulations<span class="op">$</span>T1) <span class="op">-</span><span class="st"> </span>N</a></code></pre></div>
<pre><code>[1] -1.7</code></pre>
<div class="sourceCode" id="section-cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" title="1"><span class="kw">mean</span>(thesimulations<span class="op">$</span>T2) <span class="op">-</span><span class="st"> </span>N</a></code></pre></div>
<pre><code>[1] 0.31</code></pre>
<div class="sourceCode" id="section-cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" title="1"><span class="kw">mean</span>(thesimulations<span class="op">$</span>T3) <span class="op">-</span><span class="st"> </span>N</a></code></pre></div>
<pre><code>[1] -8.9</code></pre>
<p>…it has far lower variance than <span class="math inline">\(T_{1}\)</span>…</p>
<div class="sourceCode" id="section-cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" title="1"><span class="kw">var</span>(thesimulations<span class="op">$</span>T1)</a></code></pre></div>
<pre><code>[1] 2985</code></pre>
<div class="sourceCode" id="section-cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" title="1"><span class="kw">var</span>(thesimulations<span class="op">$</span>T2)</a></code></pre></div>
<pre><code>[1] 71</code></pre>
<div class="sourceCode" id="section-cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" title="1"><span class="kw">var</span>(thesimulations<span class="op">$</span>T3)</a></code></pre></div>
<pre><code>[1] 77</code></pre>
<p>…and hence its MSE is far better than <span class="math inline">\(T_{1}\)</span>…</p>
<div class="sourceCode" id="section-cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" title="1"><span class="kw">mse</span>(thesimulations<span class="op">$</span>T1)</a></code></pre></div>
<pre><code>[1] 2988</code></pre>
<div class="sourceCode" id="section-cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" title="1"><span class="kw">mse</span>(thesimulations<span class="op">$</span>T2)</a></code></pre></div>
<pre><code>[1] 72</code></pre>
<div class="sourceCode" id="section-cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" title="1"><span class="kw">mse</span>(thesimulations<span class="op">$</span>T3)</a></code></pre></div>
<pre><code>[1] 156</code></pre>
<p>…although <span class="math inline">\(T_{2}\)</span> is still better.</p>

<div class="sourceCode" id="section-cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" title="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb216-2" title="2"><span class="kw">library</span>(patchwork)</a></code></pre></div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-statistical-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-introduction-to-bayesian-inference.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
